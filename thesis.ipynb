{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d358e94d",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tqdm import tqdm\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import kruskal, spearmanr, mannwhitneyu\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "from statsmodels.tools import add_constant\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import umap.umap_ as umap  # this sometimes doesn't load, try different ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622025d",
   "metadata": {},
   "source": [
    "# Model and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95be08f",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURATION\n",
    "IMAGE_DIR = 'PREPROCESSED_IMAGES'\n",
    "CSV_PATH = 'main.csv'\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 3\n",
    "EPOCHS = 50\n",
    "LR = 1e-4\n",
    "PATIENCE = 8\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# DATASET\n",
    "class ADNIdataset(Dataset):\n",
    "    def __init__(self, csv_path, image_dir, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_map = {label: idx for idx, label in enumerate(self.data['Group'].unique())} # map labels (AD, CN, MCI) to integers\n",
    "        self.education = self.data['PTEDUCAT'].values.astype(float).reshape(-1, 1)\n",
    "        self.genotype = pd.get_dummies(self.data['GENOTYPE']).values.astype(float)\n",
    "        self.age = self.data['Age'].values.astype(float).reshape(-1, 1)\n",
    "        self.sex = pd.get_dummies(self.data['Sex'], drop_first=True).values.astype(float)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_name = row['ImageID'] + '.png'\n",
    "\n",
    "        image_path = None\n",
    "        for subdir in os.listdir(self.image_dir):\n",
    "            full_path = os.path.join(self.image_dir, subdir, image_name)\n",
    "            if os.path.exists(full_path):\n",
    "                image_path = full_path\n",
    "                break\n",
    "\n",
    "        if image_path is None:\n",
    "            raise FileNotFoundError(f\"Image {image_name} not found.\")\n",
    "\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = torch.tensor(self.label_map[row['Group']], dtype=torch.long)\n",
    "        education_vector = torch.tensor(self.education[idx], dtype=torch.float)\n",
    "        genotype_vector = torch.tensor(self.genotype[idx], dtype=torch.float)\n",
    "        age_vector = torch.tensor(self.age[idx], dtype=torch.float)\n",
    "        sex_vector = torch.tensor(self.sex[idx], dtype=torch.float)\n",
    "        return image, label, education_vector, genotype_vector, age_vector, sex_vector\n",
    "\n",
    "# DATA AUGMENTATION\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomAffine(degrees=3, translate=(0.01, 0.01)),  # Very minor augmentation\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# DATASET (with stratisfied split)\n",
    "full_dataset = ADNIdataset(CSV_PATH, IMAGE_DIR, transform=val_transform)\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(len(full_dataset)),\n",
    "    test_size=0.2,\n",
    "    stratify=full_dataset.data['Group'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Apply different transforms\n",
    "train_dataset = ADNIdataset(CSV_PATH, IMAGE_DIR, transform=train_transform)\n",
    "train_dataset.data = full_dataset.data.iloc[train_indices].reset_index(drop=True)\n",
    "\n",
    "val_dataset = ADNIdataset(CSV_PATH, IMAGE_DIR, transform=val_transform)\n",
    "val_dataset.data = full_dataset.data.iloc[val_indices].reset_index(drop=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# CLASS BALANCING\n",
    "# Map the groups to numeric\n",
    "label_map = {'CN': 0, 'MCI': 1, 'AD': 2}\n",
    "full_dataset.data['Label'] = full_dataset.data['Group'].map(label_map)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(full_dataset.data['Label']),\n",
    "    y=full_dataset.data['Label']\n",
    ")\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee3444d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# ADD DROPOUT\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, NUM_CLASSES)\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# TRAINING LOOP WITH EARLY STOPPING AND PLOTTING\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct_train += predicted.eq(labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_loss = total_train_loss / len(train_loader)\n",
    "    train_acc = correct_train / total_train\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    best_epoch = -1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch[0].to(device)\n",
    "            labels = batch[1].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct_val += predicted.eq(labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    val_loss = total_val_loss / len(val_loader)\n",
    "    val_acc = correct_val / total_val\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train loss: {train_loss:.4f}, Train accuracy: {train_acc:.4f}, Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), 'final_best_model_end.pth')  # saved path to best final model\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(f\"The best model was from epoch {best_epoch} with val_loss = {best_val_loss:.4f}\")\n",
    "\n",
    "# PLOT TRAINING/VALIDATION LOSS AND ACCURACY\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss over Epochs')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train Accuracy')\n",
    "plt.plot(val_accs, label='Val Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy over Epochs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_plot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd37d9fb",
   "metadata": {},
   "source": [
    "### Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385e2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model architecture (same as during training)\n",
    "model = models.resnet18(pretrained=False)  # pretrained is False here, since we're loading weights\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load(\"final_best_model_end.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # Important for disabling dropout, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12c4ad",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230660a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION\n",
    "model.fc = nn.Identity()  # removes the classification head\n",
    "model.eval()\n",
    "\n",
    "feature_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "all_features, all_labels, all_education, all_genotype, all_age, all_sex = [], [], [], [], [], []\n",
    "\n",
    "# Extract feature vectors for all images \n",
    "with torch.no_grad():\n",
    "    for images, labels, education, genotype, age, sex in feature_loader:\n",
    "        images = images.to(device)\n",
    "        features = model(images).cpu().numpy()  # outputs the learned image features (not predictions) and converts from torch tensor to numpy for clustering or plotting later\n",
    "        all_features.append(features)\n",
    "        all_labels.extend(labels.numpy())  # save class labels\n",
    "        all_education.extend(education.numpy())  # save education values, etc.\n",
    "        all_genotype.extend(genotype.numpy())\n",
    "        all_age.extend(age.numpy())\n",
    "        all_sex.extend(sex.numpy())\n",
    "\n",
    "all_features = np.vstack(all_features)\n",
    "all_labels = np.array(all_labels)\n",
    "all_education = np.array(all_education)\n",
    "all_genotype = np.array(all_genotype)\n",
    "all_age = np.array(all_age)\n",
    "all_sex = np.array(all_sex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a53133",
   "metadata": {},
   "source": [
    "### Genotype values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e24823",
   "metadata": {},
   "source": [
    "Unique genotype values:\n",
    "'2/2', '2/3', '3/3', '2/4', '3/4', '4/4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9fc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genotype label mapping: {0: '2/2', 1: '2/3', 2: '2/4', 3: '3/3', 4: '3/4', 5: '4/4'}\n"
     ]
    }
   ],
   "source": [
    "# CREATE GENOTYPE LABELS TO USE FOR STATISTICAL TESTS\n",
    "genotype_labels = np.array(['2/2', '2/3', '3/3', '2/4', '3/4', '4/4'])[np.argmax(all_genotype, axis=1)]\n",
    "\n",
    "# Convert genotype_labels (strings) into integer codes (nominal category → ordinal int)\n",
    "genotype_labels_series = pd.Series(genotype_labels)\n",
    "genotype_cat = genotype_labels_series.astype('category').cat.codes.values  # e.g. \"2/2\" → 0\n",
    "\n",
    "# Here is the mapping\n",
    "label_mapping = dict(enumerate(genotype_labels_series.astype('category').cat.categories))\n",
    "print(\"Genotype label mapping:\", label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c00d689",
   "metadata": {},
   "source": [
    "# Sensitivity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d4909",
   "metadata": {},
   "source": [
    "Clustering algorithm, number of clusters, PCs and varince, UMAP hyperparameters (not fully cleared)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe1fcc2",
   "metadata": {},
   "source": [
    "### Finding number of PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99f8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA components\n",
    "\n",
    "# Input data\n",
    "X = all_features\n",
    "\n",
    "label_map_reverse = {v: k for k, v in full_dataset.label_map.items()}\n",
    "diagnosis_names = [label_map_reverse[label] for label in all_labels]\n",
    "diagnosis_labels = diagnosis_names\n",
    "\n",
    "# Range of PCA components to test\n",
    "pca_components = [10, 15, 20, 25, 30, 35, 40, 50, 60, 80, 100]\n",
    "sil_scores = []\n",
    "ari_scores = []\n",
    "\n",
    "for n_comp in pca_components:\n",
    "    # PCA\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    pca_result = pca.fit_transform(X)\n",
    "\n",
    "    # K-Means\n",
    "    #kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    #cluster_labels = kmeans.fit_predict(pca_result)\n",
    "\n",
    "    # GMM\n",
    "    gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "    cluster_labels = gmm.fit_predict(pca_result)\n",
    "\n",
    "    # Silhouette scores\n",
    "    sil = silhouette_score(pca_result, cluster_labels)\n",
    "    sil_scores.append(sil)\n",
    "\n",
    "    if diagnosis_labels is not None:\n",
    "        ari = adjusted_rand_score(diagnosis_labels, cluster_labels)\n",
    "        ari_scores.append(ari)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(pca_components, sil_scores, marker='o')\n",
    "plt.title('Silhouette Score vs PCA Components')\n",
    "plt.xlabel('Number of PCA Components')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)\n",
    "\n",
    "if diagnosis_labels is not None:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(pca_components, ari_scores, marker='o', color='darkorange')\n",
    "    plt.title('ARI vs PCA Components (Compared to Diagnosis)')\n",
    "    plt.xlabel('Number of PCA Components')\n",
    "    plt.ylabel('Adjusted Rand Index (ARI)')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c24e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PCA variance\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(all_features)\n",
    "explained_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, 101), explained_var, marker='o')\n",
    "plt.xlabel(\"Number of PCA Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Explained Variance vs PCA Components\")\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0.90, color='r', linestyle='--', label='90% Variance')\n",
    "plt.axhline(y=0.85, color='r', linestyle='--', label='85% Variance')\n",
    "plt.xticks(np.arange(0, 101, 10))  # Show every 10th tick\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Cumulative explained variance for 30 components: {explained_var[29]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7d6863",
   "metadata": {},
   "source": [
    "### Finding UMAP hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb76f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP hyperparameters\n",
    "\n",
    "X = all_features\n",
    "diagnosis_labels = diagnosis_names\n",
    "\n",
    "# Fixed PCA\n",
    "pca = PCA(n_components=30)  # 30 according to previous test\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "# UMAP parameter ranges\n",
    "n_neighbors_list = [5, 10, 15, 30, 50]\n",
    "min_dist_list = [0.0, 0.001, 0.01, 0.1, 0.3, 0.5]\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "for n_neighbors in n_neighbors_list:\n",
    "    for min_dist in min_dist_list:\n",
    "        umap_model = umap.UMAP(\n",
    "            n_neighbors=n_neighbors,\n",
    "            min_dist=min_dist,\n",
    "            n_components=2,\n",
    "            random_state=42\n",
    "        )\n",
    "        umap_result = umap_model.fit_transform(pca_result)\n",
    "\n",
    "        # K-means clustering on UMAP output\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(umap_result)\n",
    "\n",
    "        sil = silhouette_score(umap_result, cluster_labels)\n",
    "        ari = adjusted_rand_score(diagnosis_labels, cluster_labels)\n",
    "\n",
    "        results.append({\n",
    "            \"n_neighbors\": n_neighbors,\n",
    "            \"min_dist\": min_dist,\n",
    "            \"silhouette\": sil,\n",
    "            \"ari\": ari\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Plot silhouette Score\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "for n in n_neighbors_list:\n",
    "    subset = df[df[\"n_neighbors\"] == n]\n",
    "    plt.plot(subset[\"min_dist\"], subset[\"silhouette\"], marker='o', label=f'n={n}')\n",
    "\n",
    "plt.title(\"Silhouette Score vs min_dist (by n_neighbors)\")\n",
    "plt.xlabel(\"min_dist\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.legend(title=\"n_neighbors\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e56775",
   "metadata": {},
   "source": [
    "### Clustering algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187dfd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing clustering algorithms\n",
    "\n",
    "# INPUT\n",
    "X = all_features  # CNN features\n",
    "true_labels = diagnosis_names  # ['CN', 'AD', 'MCI']\n",
    "\n",
    "# Dimensionality rreduction (PCA)\n",
    "pca = PCA(n_components=30)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Clustering methods\n",
    "clustering_methods = {\n",
    "    \"KMeans (k=3)\": KMeans(n_clusters=3, random_state=42),\n",
    "    \"Agglomerative (k=3)\": AgglomerativeClustering(n_clusters=3),\n",
    "    \"DBSCAN\": DBSCAN(eps=3, min_samples=5),\n",
    "    \"GMM (k=3)\": GaussianMixture(n_components=3, random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluation\n",
    "sil_scores = []\n",
    "ari_scores = []\n",
    "labels_used = []\n",
    "\n",
    "# Loop through clustering methods\n",
    "for name, method in clustering_methods.items():\n",
    "    try:\n",
    "        if \"GMM\" in name:\n",
    "            cluster_labels = method.fit_predict(X_pca)\n",
    "        else:\n",
    "            cluster_labels = method.fit_predict(X_pca)\n",
    "\n",
    "        if len(np.unique(cluster_labels)) < 2:\n",
    "            sil = np.nan\n",
    "            ari = np.nan\n",
    "        else:\n",
    "            sil = silhouette_score(X_pca, cluster_labels)\n",
    "            ari = adjusted_rand_score(true_labels, cluster_labels)\n",
    "\n",
    "        sil_scores.append(sil)\n",
    "        ari_scores.append(ari)\n",
    "        labels_used.append(name)\n",
    "\n",
    "        print(f\"{name}\")\n",
    "        print(f\"Silhouette Score: {sil:.4f}\")\n",
    "        print(f\"Adjusted Rand Index vs Diagnosis: {ari:.4f}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {name}: {e}\")\n",
    "        sil_scores.append(np.nan)\n",
    "        ari_scores.append(np.nan)\n",
    "        labels_used.append(name)\n",
    "\n",
    "# Plot\n",
    "x = np.arange(len(labels_used))\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x - width/2, sil_scores, width, label='Silhouette Score')\n",
    "plt.bar(x + width/2, ari_scores, width, label='ARI vs Diagnosis')\n",
    "\n",
    "plt.xticks(x, labels_used, rotation=15)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Clustering Method Comparison (Silhouette score and ARI)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b90ad7",
   "metadata": {},
   "source": [
    "### Final: optimal number of K for K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f631b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal number of K for K-means\n",
    "\n",
    "X = all_features\n",
    "\n",
    "wcss = []  # store within-cluster sum of squares\n",
    "K_range = range(2, 11)  # test from 2 to 10 clusters\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)  # inertia_ = WCSS\n",
    "\n",
    "# Plot WCSS (for elbow)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(K_range, wcss, marker='o', linestyle='-')\n",
    "plt.title(\"Optimal number of clusters\")\n",
    "plt.xlabel(\"Number of Clusters (K)\")\n",
    "plt.ylabel(\"Within-Cluster Sum of Squares (WCSS)\")\n",
    "plt.xticks(K_range)  # show integer ticks for K\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118469b0",
   "metadata": {},
   "source": [
    "# Dimensionality reduction, clustering and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07303537",
   "metadata": {},
   "source": [
    "### PCA AND K-MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA + K-means\n",
    "pca = PCA(n_components=30)  # new n components\n",
    "pca_result = pca.fit_transform(all_features)\n",
    "\n",
    "# K-means\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(pca_result)\n",
    "cluster_centers_pca = kmeans.cluster_centers_\n",
    "\n",
    "# UMAP\n",
    "# Combine PCA features with cluster centers for visualisation\n",
    "combined = np.vstack([pca_result, cluster_centers_pca])\n",
    "\n",
    "# Fit UMAP on the combined data\n",
    "umap_model = umap.UMAP(n_components=2, n_neighbors=30, min_dist=0.0, random_state=42)  # new UMAP after sensitivity check\n",
    "umap_result_combined = umap_model.fit_transform(combined)\n",
    "\n",
    "# Separate points and cluster centers again\n",
    "umap_data = umap_result_combined[:-3]\n",
    "umap_centers = umap_result_combined[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cc4e97",
   "metadata": {},
   "source": [
    "### PLOT USING UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00063a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT EVERYTHING (UMAP)\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "cluster_colors = ['sandybrown', 'teal', 'mediumpurple']\n",
    "\n",
    "# Plot each cluster with a fixed color\n",
    "num_clusters = len(np.unique(cluster_labels))\n",
    "for i in range(num_clusters):\n",
    "    indices = np.where(cluster_labels == i)[0]\n",
    "    plt.scatter(umap_data[indices, 0], umap_data[indices, 1],\n",
    "                c=cluster_colors[i], label=f'Cluster {i}', alpha=0.6, s=40)\n",
    "    \n",
    "plt.scatter(umap_centers[:, 0], umap_centers[:, 1], c='black', s=200, marker='X', label='Cluster Centers')\n",
    "\n",
    "# Annotate each cluster center with its cluster number\n",
    "for i, (x, y) in enumerate(umap_centers):\n",
    "    plt.text(x + 0.3, y, f'Cluster {i}', fontsize=12, fontweight='bold', color='black')\n",
    "    \n",
    "plt.title('UMAP of CNN activations coloured by Cluster')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Map integer labels back to original diagnosis group names\n",
    "label_map_reverse = {v: k for k, v in full_dataset.label_map.items()}\n",
    "diagnosis_names = [label_map_reverse[label] for label in all_labels]\n",
    "color_map = {\n",
    "    'AD': 'indianred',\n",
    "    'MCI': 'mediumseagreen',\n",
    "    'CN': 'cornflowerblue'\n",
    "}\n",
    "\n",
    "# Plot diagnosis\n",
    "plt.figure(figsize=(10, 8))\n",
    "for group in np.unique(diagnosis_names):\n",
    "    indices = [i for i, x in enumerate(diagnosis_names) if x == group]\n",
    "    plt.scatter(umap_data[indices, 0], umap_data[indices, 1], label=group, alpha=0.6, s=40, c=color_map[group])\n",
    "plt.scatter(umap_centers[:, 0], umap_centers[:, 1], c='black', s=150, marker='X', label='Cluster Centers')\n",
    "plt.legend()\n",
    "plt.title('UMAP of CNN activations coloured by Diagnosis')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot education\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(umap_data[:, 0], umap_data[:, 1], c=all_education, cmap='viridis', alpha=0.7)\n",
    "plt.scatter(umap_centers[:, 0], umap_centers[:, 1], c='black', s=200, marker='X', label='Cluster Centers')\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Years of Education')\n",
    "plt.title('UMAP of CNN activations coloured by Education')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot genotype\n",
    "unique_labels, genotype_numeric = np.unique(genotype_labels, return_inverse=True)  # encode labels as categorical integer codes (0 to n_categories-1)\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(umap_data[:, 0], umap_data[:, 1], c=genotype_numeric, cmap='plasma', alpha=0.7)\n",
    "plt.scatter(umap_centers[:, 0], umap_centers[:, 1], c='black', s=200, marker='X', label='Cluster Centers')\n",
    "# Create colourbar\n",
    "cbar = plt.colorbar(scatter, ticks=np.arange(len(unique_labels)))\n",
    "cbar.ax.set_yticklabels(unique_labels)\n",
    "cbar.set_label('Genotype APOE')\n",
    "plt.title('UMAP of CNN activations coloured by Genotype')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot age\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(umap_data[:, 0], umap_data[:, 1], c=all_age, cmap='cividis', alpha=0.7)\n",
    "plt.scatter(umap_centers[:, 0], umap_centers[:, 1], c='black', s=200, marker='X', label='Cluster Centers')\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Age')\n",
    "plt.title('UMAP of CNN activations coloured by Age')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot sex\n",
    "sex_labels = np.where(all_sex == 1, 'M', 'F')  # convert to string labels for plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Plot M in blue\n",
    "indices_m = np.where(sex_labels == 'M')[0]\n",
    "plt.scatter(umap_data[indices_m, 0], umap_data[indices_m, 1],\n",
    "            label='M', alpha=0.6, s=40, c='mediumseagreen')\n",
    "# Plot F in red\n",
    "indices_f = np.where(sex_labels == 'F')[0]\n",
    "plt.scatter(umap_data[indices_f, 0], umap_data[indices_f, 1],\n",
    "            label='F', alpha=0.6, s=40, c='orchid')\n",
    "# Plot cluster centers\n",
    "plt.scatter(umap_centers[:, 0], umap_centers[:, 1],\n",
    "            c='black', s=150, marker='X', label='Cluster Centers')\n",
    "plt.legend()\n",
    "plt.title('UMAP of CNN activations coloured by Sex')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e3d90",
   "metadata": {},
   "source": [
    "### Distribution plots by diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map integer labels back to original diagnosis group names\n",
    "label_map_reverse = {v: k for k, v in full_dataset.label_map.items()}\n",
    "diagnosis_names = [label_map_reverse[label] for label in all_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT KDE DISTRUBUTIONS (FOR CONTINOUS VARIABLES EDUCATION AND AGE)\n",
    "\n",
    "# EDUCATION\n",
    "df_plot = pd.DataFrame({\n",
    "    'Education': np.array(all_education).flatten(),\n",
    "    'Diagnosis': diagnosis_names\n",
    "})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(\n",
    "    data=df_plot,\n",
    "    x=\"Education\",\n",
    "    hue=\"Diagnosis\",\n",
    "    fill=True,\n",
    "    common_norm=False, # normalise\n",
    "    alpha=0.4,\n",
    "    linewidth=2,\n",
    "    palette={\"CN\": \"cornflowerblue\", \"MCI\": \"mediumseagreen\", \"AD\": \"red\"}\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Years of Education\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of Education by Diagnosis group\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# AGE\n",
    "df_plot = pd.DataFrame({\n",
    "    'Age': np.array(all_age).flatten(),\n",
    "    'Diagnosis': diagnosis_names\n",
    "})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(\n",
    "    data=df_plot,\n",
    "    x=\"Age\",\n",
    "    hue=\"Diagnosis\",\n",
    "    fill=True,\n",
    "    common_norm=False,  # normalise\n",
    "    alpha=0.4,\n",
    "    linewidth=2,\n",
    "    palette={\"CN\": \"cornflowerblue\", \"MCI\": \"mediumseagreen\", \"AD\": \"red\"}\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of Age by Diagnosis group\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e92fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAR PLOTS DISTRIBUTIONS (FOR CATEGORICAL VARIABLES GENOTYPE AND SEX)\n",
    "\n",
    "# SEX\n",
    "df_plot_sex = pd.DataFrame({\n",
    "    'Sex': np.array(all_sex).flatten(),  # 0 = one sex, 1 = the other\n",
    "    'Diagnosis': diagnosis_names\n",
    "})\n",
    "sex_map = {0: 'F', 1: 'M'}\n",
    "df_plot_sex['Sex'] = df_plot_sex['Sex'].map(sex_map)\n",
    "\n",
    "# Count and normalise\n",
    "df_plot_sex['count'] = 1\n",
    "sex_counts = df_plot_sex.groupby(['Diagnosis', 'Sex'])['count'].sum().reset_index()\n",
    "total_per_diagnosis = sex_counts.groupby('Diagnosis')['count'].transform('sum')\n",
    "sex_counts['proportion'] = sex_counts['count'] / total_per_diagnosis\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(\n",
    "    data=sex_counts,\n",
    "    x='Sex',\n",
    "    y='proportion',\n",
    "    hue='Diagnosis',\n",
    "    palette={\"CN\": \"cornflowerblue\", \"MCI\": \"mediumseagreen\", \"AD\": \"red\"}\n",
    ")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.title(\"Distribution of Sex by Diagnosis Group\")\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# GENOTYPE\n",
    "ordered_genotypes = ['2/2', '2/3', '3/3', '2/4', '3/4', '4/4']\n",
    "genotype_cat = pd.Categorical(genotype_labels, categories=ordered_genotypes, ordered=True)\n",
    "genotype_numeric = genotype_cat.codes  # these are 0–5, matching the order above\n",
    "\n",
    "df_plot_genotype = pd.DataFrame({\n",
    "    'Genotype': genotype_cat,\n",
    "    'Diagnosis': diagnosis_names\n",
    "})\n",
    "\n",
    "# Count and normalise\n",
    "df_plot_genotype['count'] = 1\n",
    "geno_counts = df_plot_genotype.groupby(['Diagnosis', 'Genotype'])['count'].sum().reset_index()\n",
    "total_per_diag = geno_counts.groupby('Diagnosis')['count'].transform('sum')\n",
    "geno_counts['proportion'] = geno_counts['count'] / total_per_diag\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(\n",
    "    data=geno_counts,\n",
    "    x='Genotype',\n",
    "    y='proportion',\n",
    "    hue='Diagnosis',\n",
    "    palette={\"CN\": \"cornflowerblue\", \"MCI\": \"mediumseagreen\", \"AD\": \"red\"}\n",
    ")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.title(\"Distribution of Genotype by Diagnosis Group\")\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about distribution of genotype and diagnosis\n",
    "\n",
    "df_plot = pd.DataFrame({\n",
    "    'GenotypeNumeric': genotype_numeric,\n",
    "    'GenotypeLabel': genotype_labels,\n",
    "    'Diagnosis': diagnosis_names\n",
    "})\n",
    "\n",
    "df_plot.groupby(['Diagnosis', 'GenotypeLabel']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29b6866",
   "metadata": {},
   "source": [
    "# Statistical tests and evaluation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5636de8",
   "metadata": {},
   "source": [
    "### Silhouette score, Kruskal-Wallis, clusterwise summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3173da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICAL ANALYSIS\n",
    "\n",
    "# SILHOUETTE SCORE\n",
    "sil_score = silhouette_score(pca_result, cluster_labels)\n",
    "print(f\"Silhouette Score: {sil_score:.4f}\")\n",
    "\n",
    "# KRUSKAL–WALLIS TEST\n",
    "# diagnosis differences between clusters\n",
    "diagnosis_by_cluster = [all_labels[np.array(cluster_labels) == i].ravel() for i in np.unique(cluster_labels)]\n",
    "kruskal_stat_d, kruskal_p_d = kruskal(*diagnosis_by_cluster)\n",
    "print(f\"Kruskal–Wallis Test (Diagnosis): H={float(kruskal_stat_d):.4f}, p={float(kruskal_p_d):.4e}\")\n",
    "\n",
    "# education differences between clusters\n",
    "education_by_cluster = [all_education[np.array(cluster_labels) == i].ravel() for i in np.unique(cluster_labels)]\n",
    "kruskal_stat_ed, kruskal_p_ed = kruskal(*education_by_cluster)\n",
    "print(f\"Kruskal–Wallis Test (Education): H={float(kruskal_stat_ed):.4f}, p={float(kruskal_p_ed):.4e}\")\n",
    "\n",
    "# genotype differences between clusters as NOMINAL\n",
    "genotype_by_cluster = [genotype_cat[np.array(cluster_labels) == i] for i in np.unique(cluster_labels)]  # group the coded genotypes by cluster\n",
    "kruskal_stat_g, kruskal_p_g = kruskal(*genotype_by_cluster)\n",
    "print(f\"Kruskal–Wallis Test (Genotype as Nnminal): H={float(kruskal_stat_g):.4f}, p={float(kruskal_p_g):.4e}\")\n",
    "\n",
    "# age differences between clusters\n",
    "age_by_cluster = [all_age[np.array(cluster_labels) == i].ravel() for i in np.unique(cluster_labels)]\n",
    "kruskal_stat_age, kruskal_p_age = kruskal(*age_by_cluster)\n",
    "print(f\"Kruskal–Wallis Test (Age): H={float(kruskal_stat_age):.4f}, p={float(kruskal_p_age):.4e}\")\n",
    "\n",
    "# sex differences between clusters\n",
    "sex_by_cluster = [all_sex[np.array(cluster_labels) == i].ravel() for i in np.unique(cluster_labels)]\n",
    "kruskal_stat_sex, kruskal_p_sex = kruskal(*sex_by_cluster)\n",
    "print(f\"Kruskal–Wallis Test (Sex): H={float(kruskal_stat_sex):.4f}, p={float(kruskal_p_sex):.4e}\")\n",
    "\n",
    "# CLUSTERWISE SUMMARY STATISTICS\n",
    "df = pd.DataFrame({\n",
    "    'Cluster': cluster_labels.ravel(),\n",
    "    'Diagnosis': all_labels.ravel(),\n",
    "    'Education': all_education.ravel(),\n",
    "    'GenotypeIndex': genotype_cat.ravel(),\n",
    "    'GenotypeNumeric': genotype_numeric.ravel(),\n",
    "    'Age': all_age.ravel(),\n",
    "    'Sex': all_sex.ravel()\n",
    "})\n",
    "\n",
    "# Summary diagnosis\n",
    "summary_d = df.groupby('Cluster')['Diagnosis'].agg(['count', 'mean', 'median', 'std'])\n",
    "print(\"\\Diagnosis Stats per Cluster:\")\n",
    "print(summary_d)\n",
    "# Summary education\n",
    "summary_ed = df.groupby('Cluster')['Education'].agg(['count', 'mean', 'median', 'std'])\n",
    "print(\"\\nEducation Stats per Cluster:\")\n",
    "print(summary_ed) \n",
    "# Summary genotype\n",
    "summary_g = df.groupby('Cluster')['GenotypeNumeric'].agg(['count', 'mean', 'median', 'std'])\n",
    "print(\"Genotype Stats per Cluster:\")\n",
    "print(summary_g)\n",
    "# Summary age\n",
    "summary_age = df.groupby('Cluster')['Age'].agg(['count', 'mean', 'median', 'std'])\n",
    "print(\"\\Age Stats per Cluster:\")\n",
    "print(summary_age) \n",
    "# Summary age\n",
    "summary_sex = df.groupby('Cluster')['Sex'].agg(['count', 'mean', 'median', 'std'])\n",
    "print(\"\\Sex Stats per Cluster:\")\n",
    "print(summary_sex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f86085",
   "metadata": {},
   "source": [
    "### Post-hoc Mann-Whitney U test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af9cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc pairwise test\n",
    "# Specifically if there are any differences between any 2 pairs of clusters\n",
    "# Since we proved that all except age show differences, these are tested\n",
    "\n",
    "# ANALYSIS OF DIAGNOSIS\n",
    "unique_clusters = np.unique(cluster_labels)\n",
    "comparisons = []\n",
    "p_values = []\n",
    "\n",
    "# Pairwise Mann–Whitney U tests\n",
    "for i in range(len(unique_clusters)):\n",
    "    for j in range(i + 1, len(unique_clusters)):\n",
    "        c1 = unique_clusters[i]\n",
    "        c2 = unique_clusters[j]\n",
    "        \n",
    "        group1 = all_labels[np.array(cluster_labels) == c1]\n",
    "        group2 = all_labels[np.array(cluster_labels) == c2]\n",
    "        \n",
    "        stat, p = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "        comparisons.append(f\"{c1} vs {c2}\")\n",
    "        p_values.append(p)\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "p_values = np.array(p_values).flatten()\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, method='bonferroni')\n",
    "\n",
    "# Print\n",
    "print(\"\\nPost-hoc Mann–Whitney U Tests for Diagnosis (Bonferroni corrected):\\n\")\n",
    "print(f\"{'Comparison':<10}, {'Raw p-value':<12}, {'Bonferroni p':<14}, {'Significant'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i in range(len(comparisons)):\n",
    "    print(f\"{comparisons[i]:<10} | {p_values[i]:<12.4e} | {pvals_corrected[i]:<14.4e} | {reject[i]}\")\n",
    "\n",
    "\n",
    "# ANALYSIS OF EDUCATION\n",
    "unique_clusters = np.unique(cluster_labels)\n",
    "comparisons = []\n",
    "p_values = []\n",
    "\n",
    "# Pairwise Mann–Whitney U tests\n",
    "for i in range(len(unique_clusters)):\n",
    "    for j in range(i + 1, len(unique_clusters)):\n",
    "        c1 = unique_clusters[i]\n",
    "        c2 = unique_clusters[j]\n",
    "        \n",
    "        group1 = all_education[np.array(cluster_labels) == c1]\n",
    "        group2 = all_education[np.array(cluster_labels) == c2]\n",
    "        \n",
    "        stat, p = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "        comparisons.append(f\"{c1} vs {c2}\")\n",
    "        p_values.append(p)\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "p_values = np.array(p_values).flatten()\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, method='bonferroni')\n",
    "\n",
    "# Print\n",
    "print(\"\\nPost-hoc Mann–Whitney U Tests for Education (Bonferroni corrected):\\n\")\n",
    "print(f\"{'Comparison':<10}, {'Raw p-value':<12}, {'Bonferroni p':<14}, {'Significant'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i in range(len(comparisons)):\n",
    "    print(f\"{comparisons[i]:<10} | {p_values[i]:<12.4e} | {pvals_corrected[i]:<14.4e} | {reject[i]}\")\n",
    "\n",
    "\n",
    "# ANALYSIS OF GENOTYPE\n",
    "unique_clusters = np.unique(cluster_labels)\n",
    "comparisons = []\n",
    "p_values = []\n",
    "\n",
    "# Pairwise Mann–Whitney U tests\n",
    "for i in range(len(unique_clusters)):\n",
    "    for j in range(i + 1, len(unique_clusters)):\n",
    "        c1 = unique_clusters[i]\n",
    "        c2 = unique_clusters[j]\n",
    "        \n",
    "        group1 = genotype_cat[np.array(cluster_labels) == c1]\n",
    "        group2 = genotype_cat[np.array(cluster_labels) == c2]\n",
    "        \n",
    "        stat, p = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "        comparisons.append(f\"{c1} vs {c2}\")\n",
    "        p_values.append(p)\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "p_values = np.array(p_values).flatten()\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, method='bonferroni')\n",
    "\n",
    "# Print\n",
    "print(\"\\nPost-hoc Mann–Whitney U Tests for Genotype (Bonferroni corrected):\\n\")\n",
    "print(f\"{'Comparison':<10}, {'Raw p-value':<12}, {'Bonferroni p':<14}, {'Significant'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i in range(len(comparisons)):\n",
    "    print(f\"{comparisons[i]:<10} | {p_values[i]:<12.4e} | {pvals_corrected[i]:<14.4e} | {reject[i]}\")    \n",
    "\n",
    "\n",
    "# ANALYSIS OF SEX\n",
    "unique_clusters = np.unique(cluster_labels)\n",
    "comparisons = []\n",
    "p_values = []\n",
    "\n",
    "# Pairwise Mann–Whitney U tests\n",
    "for i in range(len(unique_clusters)):\n",
    "    for j in range(i + 1, len(unique_clusters)):\n",
    "        c1 = unique_clusters[i]\n",
    "        c2 = unique_clusters[j]\n",
    "        \n",
    "        group1 = all_sex[np.array(cluster_labels) == c1]\n",
    "        group2 = all_sex[np.array(cluster_labels) == c2]\n",
    "        \n",
    "        stat, p = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "        comparisons.append(f\"{c1} vs {c2}\")\n",
    "        p_values.append(p)\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "p_values = np.array(p_values).flatten()\n",
    "reject, pvals_corrected, _, _ = multipletests(p_values, method='bonferroni')\n",
    "\n",
    "# Print\n",
    "print(\"\\nPost-hoc Mann–Whitney U Tests for Sex (Bonferroni corrected):\\n\")\n",
    "print(f\"{'Comparison':<10}, {'Raw p-value':<12}, {'Bonferroni p':<14}, {'Significant'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i in range(len(comparisons)):\n",
    "    print(f\"{comparisons[i]:<10} | {p_values[i]:<12.4e} | {pvals_corrected[i]:<14.4e} | {reject[i]}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3964b",
   "metadata": {},
   "source": [
    "### ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc611a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted Rand Index (ARI) between clusters and diagnosis\n",
    "ari = adjusted_rand_score(all_labels, cluster_labels)\n",
    "print(f\"Adjusted Rand Index (Clusters vs Diagnosis): {ari:.4f}\")\n",
    "\n",
    "# Just for curiosity:\n",
    "ari = adjusted_rand_score(all_labels, all_education.ravel())\n",
    "print(f\"Adjusted Rand Index (Clusters vs Education): {ari:.4f}\")\n",
    "\n",
    "ari = adjusted_rand_score(all_labels, genotype_cat)\n",
    "print(f\"Adjusted Rand Index (Clusters vs Genotype): {ari:.4f}\")\n",
    "\n",
    "ari = adjusted_rand_score(all_labels, all_age.ravel())\n",
    "print(f\"Adjusted Rand Index (Clusters vs Age): {ari:.4f}\")\n",
    "\n",
    "ari = adjusted_rand_score(all_labels, all_sex.ravel())\n",
    "print(f\"Adjusted Rand Index (Clusters vs Sex): {ari:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ab578",
   "metadata": {},
   "source": [
    "For analysing the above:\n",
    "Most Common Diagnosis per Cluster:\n",
    "Cluster 0 → CN\n",
    "Cluster 1 → AD\n",
    "Cluster 2 → MCI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057084b5",
   "metadata": {},
   "source": [
    "### MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Logistic Regression for predicting Clusters\n",
    "\n",
    "df_multi = pd.DataFrame({\n",
    "    'Cluster': cluster_labels,\n",
    "    'Diagnosis': all_labels.ravel(),\n",
    "    'Education': all_education.ravel(),\n",
    "    'GenotypeIndex': genotype_cat.ravel(),\n",
    "    'Age': all_age.ravel(),\n",
    "    'Sex': all_sex.ravel()\n",
    "})\n",
    "\n",
    "# Convert to categorical for regression\n",
    "df_multi['GenotypeIndex'] = pd.Categorical(genotype_cat)\n",
    "df_multi['Diagnosis'] = pd.Categorical(df_multi['Diagnosis'])\n",
    "\n",
    "# Cluster 0 (CN) as baseline\n",
    "logit_model = sm.MNLogit(df_multi['Cluster'], sm.add_constant(df_multi[['Diagnosis', 'Education', 'GenotypeIndex', 'Age', 'Sex']]))\n",
    "result = logit_model.fit(disp=False)\n",
    "print(\"\\nMultinomial Logistic Regression (Cluster ~ Diagnosis + Education + Genotype + Age + Sex):\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d44bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi['Cluster'] = pd.Categorical(df_multi['Cluster'], categories=[1, 0, 2])  # now Cluster 1 is baseline\n",
    "\n",
    "# Refit MLR with new baseline\n",
    "logit_model = sm.MNLogit(df_multi['Cluster'], sm.add_constant(df_multi[['Diagnosis', 'Education', 'GenotypeIndex', 'Age', 'Sex']]))\n",
    "result = logit_model.fit(disp=False)\n",
    "\n",
    "print(\"\\nMultinomial Logistic Regression (Cluster ~ Diagnosis + Education + Genotype + Age + Sex) [Cluster 1 as baseline]:\")\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821b902",
   "metadata": {},
   "source": [
    "### PCA component correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe60e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Component Correlations\n",
    "\n",
    "pca_features = pca_result[:, :10]  # first 10 principal components\n",
    "\n",
    "def correlate_pcs(pca_features, external_variable, variable_name):\n",
    "    print(f\"\\nTop PCA Components Correlated with {variable_name}:\")\n",
    "    for i in range(pca_features.shape[1]):\n",
    "        r, p = spearmanr(pca_features[:, i], external_variable.ravel())\n",
    "        print(f\"PC{i+1}: Spearman r={r:.4f}, p={p:.2e}\")\n",
    "\n",
    "correlate_pcs(pca_features, diagnosis_numeric, 'Diagnosis')\n",
    "correlate_pcs(pca_features, all_education, 'Education')\n",
    "correlate_pcs(pca_features, all_age, 'Age')\n",
    "correlate_pcs(pca_features, genotype_cat, 'GenotypeIndex')\n",
    "correlate_pcs(pca_features, all_sex, 'Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24befba5",
   "metadata": {},
   "source": [
    "### Feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89630990",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_feature_maps(model, image_tensor, layer, num_maps=8, layer_name=\"\"):\n",
    "    activation = {}\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        activation['features'] = output.detach().cpu()\n",
    "\n",
    "    # Register forward hook\n",
    "    handle = layer.register_forward_hook(hook_fn)\n",
    "\n",
    "    # Forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(image_tensor.to(device))\n",
    "\n",
    "    handle.remove()\n",
    "\n",
    "    # Get feature maps\n",
    "    features = activation['features'].squeeze(0)  # shape: (C, H, W)\n",
    "    num_maps = min(num_maps, features.shape[0])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(num_maps):\n",
    "        plt.subplot(1, num_maps, i + 1)\n",
    "        plt.imshow(features[i], cmap='viridis')\n",
    "        plt.title(f'Map {i}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f'Feature Maps (Layer {layer_name})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# RUN EXAMPLE\n",
    "# Load a random image\n",
    "sample_loader = DataLoader(full_dataset, batch_size=1, shuffle=True)\n",
    "sample_img_batch = next(iter(sample_loader))\n",
    "sample_img = sample_img_batch[0].to(device)  # [0] = image, others = label + extras\n",
    "\n",
    "# Plot from key layers of ResNet-18\n",
    "layers_to_plot = [\n",
    "    (model.conv1, \"0\"),\n",
    "    (model.layer1[0].conv1, \"1\"),\n",
    "    (model.layer2[0].conv1, \"2\"),\n",
    "    (model.layer3[0].conv1, \"3\"),\n",
    "    (model.layer4[0].conv1, \"4\"),\n",
    "]\n",
    "\n",
    "for layer, name in layers_to_plot:\n",
    "    plot_feature_maps(model, sample_img, layer, num_maps=6, layer_name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed3d4b",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b8983",
   "metadata": {},
   "source": [
    "## Overall cluster information and different sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO CHECK HOW MANY DIAGNOSIS IN EACH CLUSTER\n",
    "\n",
    "df_cluster_diagnosis = pd.DataFrame({\n",
    "    'Cluster': cluster_labels,\n",
    "    'Diagnosis': diagnosis_labels  # or diagnosis_names if you have string labels\n",
    "})\n",
    "\n",
    "# Crosstab counts of diagnoses in each cluster\n",
    "crosstab = pd.crosstab(df_cluster_diagnosis['Cluster'], df_cluster_diagnosis['Diagnosis'])\n",
    "\n",
    "# Normalise to get percentages\n",
    "crosstab_percent = crosstab.div(crosstab.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Print results\n",
    "print(\"Diagnosis Counts per Cluster:\")\n",
    "print(crosstab)\n",
    "print(\"\\nDiagnosis Percentages per Cluster:\")\n",
    "print(crosstab_percent.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e488c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_reverse = {v: k for k, v in full_dataset.label_map.items()}\n",
    "print(\"Label Map:\", label_map_reverse)\n",
    "\n",
    "diagnosis_numeric = np.array([label_map[label] for label in diagnosis_labels])\n",
    "\n",
    "# LABEL MAP IS NOT THE SAME AS THE CLUSTER ORDER!!!! DO NOT MIND THE LABEL MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2805f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapping = pd.DataFrame({\n",
    "    'Cluster': cluster_labels,\n",
    "    'Diagnosis': diagnosis_numeric.ravel()\n",
    "})\n",
    "\n",
    "# Count how many of each diagnosis per cluster\n",
    "counts = pd.crosstab(df_mapping['Cluster'], df_mapping['Diagnosis'])\n",
    "\n",
    "# Find most common diagnosis per cluster\n",
    "dominant_labels = counts.idxmax(axis=1)  # gives the diagnosis index\n",
    "dominant_labels_named = dominant_labels.map(label_map)  # convert to names\n",
    "\n",
    "label_map_reverse = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Print\n",
    "print(\"Most Common Diagnosis per Cluster:\\n\")\n",
    "for cluster_id, diag_index in dominant_labels.items():\n",
    "    label_name = label_map_reverse[int(diag_index)]\n",
    "    print(f\"Cluster {cluster_id} → {label_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde804fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_map = {0: 'F', 1: 'M'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c8a24",
   "metadata": {},
   "source": [
    "## ANCOVA (not used anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOCOVA\n",
    "\n",
    "# Flatten just in case\n",
    "education_flat = all_education.ravel()\n",
    "cluster_labels_flat = np.array(cluster_labels).ravel()\n",
    "diagnosis_flat = np.array(all_labels).ravel()\n",
    "age_flat = np.array(all_age).ravel()\n",
    "sex_flat = np.array(all_sex).ravel()\n",
    "\n",
    "df_ancova = pd.DataFrame({\n",
    "    'Education': education_flat,\n",
    "    'Cluster': cluster_labels_flat.astype(str),\n",
    "    'Diagnosis': diagnosis_flat.astype(str),\n",
    "    'Age': age_flat,\n",
    "    'GenotypeIndex': genotype_strength,\n",
    "    'Sex': sex_flat\n",
    "})\n",
    "\n",
    "# ANCOVA: Does education differ by cluster, after accounting for diagnosis?\n",
    "model = ols('Education ~ C(Cluster) + C(Diagnosis)', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (Education ~ Cluster + Diagnosis):\")\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# ANCOVA: Does genotype differ by cluster, after accounting for diagnosis?\n",
    "model = ols('GenotypeIndex ~ C(Cluster) + C(Diagnosis)', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (GenotypeIndex ~ Cluster + Diagnosis):\")\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# ANCOVA: Does age differ by cluster, after accounting for diagnosis?\n",
    "model = ols('Age ~ C(Cluster) + C(Diagnosis)', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (Age ~ Cluster + Diagnosis):\")\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# ANCOVA: Does sex differ by cluster, after accounting for diagnosis?\n",
    "model = ols('Sex ~ C(Cluster) + C(Diagnosis)', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (Sex ~ Cluster + Diagnosis):\")\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# ANCOVA: Does education differ by cluster, after accounting for age?\n",
    "model = ols('Education ~ C(Cluster) + Age', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (Education ~ Cluster + Age):\")\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# ANCOVA: Does genotype differ by cluster, after accounting for age?\n",
    "model = ols('GenotypeIndex ~ C(Cluster) + Age', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (GenotypeIndex ~ Cluster + Age):\")\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# ANCOVA: Does education differ by cluster, after accounting for sex?\n",
    "model = ols('Education ~ C(Cluster) + Sex', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (Education ~ Cluster + Sex):\")\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# ANCOVA: Does genotype differ by cluster, after accounting for sex?\n",
    "model = ols('GenotypeIndex ~ C(Cluster) + Sex', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (GenotypeIndex ~ Cluster + Sex):\")\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# ANCOVA: Does education differ by cluster, after accounting for age + diagnosis + sex?\n",
    "model = ols('Education ~ C(Cluster) + Age + C(Diagnosis) + Sex', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (Education ~ Cluster + Age + Diangosis + Sex):\")\n",
    "print(anova_table.round(4))\n",
    "\n",
    "# ANCOVA: Does genotype differ by cluster, after accounting for age + diagnosis + sex?\n",
    "model = ols('GenotypeIndex ~ C(Cluster) + Age + C(Diagnosis) + Sex', data=df_ancova).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(\"ANCOVA (GenotypeIndex ~ Cluster + Age + Diangosis + Sex):\")\n",
    "print(anova_table.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4af33fc",
   "metadata": {},
   "source": [
    "## Assumption checks for MLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce8835",
   "metadata": {},
   "source": [
    "### Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5992a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for linearity\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    'Diagnosis': all_labels.ravel(),\n",
    "    'Education': all_education.ravel(),\n",
    "    'GenotypeIndex': genotype_cat.ravel(),\n",
    "    'Age': all_age.ravel(),\n",
    "    'Sex': all_sex.ravel()\n",
    "})\n",
    "y = pd.Series(cluster_labels, name='Cluster')\n",
    "\n",
    "#X['GenotypeIndex'] = X['GenotypeIndex'].astype('category') # to use categorical in MLR\n",
    "\n",
    "# Log-transform some variables\n",
    "#X['Age_log'] = np.log(X['Age'] + 1)\n",
    "#X['Genotype_log'] = np.log(X['GenotypeIndex'] + 1)\n",
    "\n",
    "# Predictors to check\n",
    "predictors = ['Diagnosis', 'Education', 'GenotypeIndex', 'Age', 'Sex']\n",
    "X_model = sm.add_constant(X[predictors])\n",
    "\n",
    "# Fit MLR\n",
    "mlr_model = sm.MNLogit(y, X_model).fit(disp=False)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = mlr_model.predict(X_model)\n",
    "probs.columns = ['P(Cluster=0)', 'P(Cluster=1)', 'P(Cluster=2)']\n",
    "\n",
    "# Predictor vs. predicted probability for each cluster\n",
    "for predictor in predictors:\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    \n",
    "    for i in range(3):  # for each cluster class\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        sns.scatterplot(x=X[predictor], y=probs.iloc[:, i], alpha=0.4)\n",
    "        sns.regplot(x=X[predictor], y=probs.iloc[:, i], scatter=False, color='red', lowess=True)\n",
    "        plt.title(f'{predictor} vs P(Cluster={i})')\n",
    "        plt.xlabel(predictor)\n",
    "        plt.ylabel(f'P(Cluster={i})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479225dc",
   "metadata": {},
   "source": [
    "### Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.DataFrame({\n",
    "    'Diagnosis': all_labels.ravel(),\n",
    "    'Education': all_education.ravel(),\n",
    "    'GenotypeIndex': genotype_cat.ravel(),\n",
    "    'Age': all_age.ravel(),\n",
    "    'Sex': all_sex.ravel()\n",
    "})\n",
    "\n",
    "y = cluster_labels.ravel()\n",
    "X = add_constant(X)\n",
    "\n",
    "# Fit MLR\n",
    "mlr_model = MNLogit(y, X).fit()\n",
    "predicted_probs = mlr_model.predict(X)\n",
    "\n",
    "# Get residuals (raw residuals from predicted class probs)\n",
    "residuals = []\n",
    "for i in range(len(y)):\n",
    "    true_class = y[i]\n",
    "    residual = 1 - predicted_probs.iloc[i, true_class]\n",
    "    residuals.append(residual)\n",
    "\n",
    "residuals = np.array(residuals)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals, kde=True, color='steelblue')\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q–Q Plot of Residuals\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals are not required, for this is not a classification task\n",
    "\n",
    "ks_stat, ks_p = stats.kstest(residuals, 'norm', args=(np.mean(residuals), np.std(residuals)))\n",
    "print(f\"Kolmogorov–Smirnov Test: D = {ks_stat:.4f}, p = {ks_p:.4e}\")\n",
    "\n",
    "if ks_p > 0.05:\n",
    "    print(\"Residuals appear to follow a normal distribution (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Residuals deviate from normal distribution (reject H0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17849a24",
   "metadata": {},
   "source": [
    "### No multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d839ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.DataFrame({\n",
    "    'Diagnosis': all_labels.ravel(),\n",
    "    'Education': all_education.ravel(),\n",
    "    'GenotypeIndex': genotype_cat.ravel(),\n",
    "    'Age': all_age.ravel(),\n",
    "    'Sex': all_sex.ravel()\n",
    "})\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(X.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Predictors\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Variance Inflation Factor (VIF)\n",
    "X_with_const = X.copy()\n",
    "X_with_const['Intercept'] = 1\n",
    "\n",
    "# Compute VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Feature'] = X_with_const.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X_with_const.values, i)\n",
    "                   for i in range(X_with_const.shape[1])]\n",
    "\n",
    "# Drop intercept row from VIF table\n",
    "vif_data = vif_data[vif_data['Feature'] != 'Intercept']\n",
    "\n",
    "print(\"\\nVariance Inflation Factor (VIF):\")\n",
    "print(vif_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.7.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
